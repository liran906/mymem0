## 关于我们的pipeline

阶段1
我觉得可以把我们的字段结构（全量）放到prompt中，
然后把原始的信息给llm，让llm判断在给他的信息中是否涉及到相关的字段，
如果涉及，比如用户说，”我昨天搬家了，新家位于北京“，那么此时就要求llm返回：
json：{"basic_info":{"location":"Beijing"}}
或者用户说了多个涉及字段的点，比如“我昨天搬家了，新家位于北京，爸妈把我最爱的足球忘了没带过来，但还好北京有好吃的烤鸭”
那么此时就要求llm返回：
json：{"basic_info":{"location":"Beijing"}}
json：{"interests":["football", "北京烤鸭"]}
也就是第一阶段提取相关信息到给定的字段

这里我也提出一个疑问，我们是否要按照中文保存？因为我们主要的用户都是中国人。

阶段2
拿到阶段1的结果之后，这个阶段的llm再做更新决策（参考mem0）
把相关信息，比如
原始json：{"basic_info":{"location":"Nanjing"}}
和传入的json：{"basic_info":{"location":"Beijing"}}
做对比，得出是update，然后执行数据库操作

当然这其中关于容错的设计，还有其他的设计，我觉得都可以借鉴mem0的做法。

你说的“每个顶级字段（basic_info, interests, skills 等）独立处理”是指每一次llm
生成多个json吗？每个顶级字段一个？

你觉得怎么样？是否需要补充或者完善？

## 关于 dislike 字段（你的第4点）

我有个想法，在interest中增加一个degree字段，是enum，可以是：
"hate","dislike","neutral","like","love"
仅仅针对对话中提到过的兴趣才有，这样就可以update了。
你觉得这个方案比之前的怎么样？可行性如何？考虑到llm可能出现的不稳定之后，综合评估如何？

## 关于表结构

用户基本信息中，bio和aratar其实在用户表（主代码中）肯定有，我们这里只是用于用户特征的用户特征表，
所以我觉得不需要。我们这需要的仅仅是能作为上下文提供给对话llm来增强对话体验的信息
带着这个mindset，你再看看表结构是否需要新的字段。

user_vocabulary和user_additional_profile我看了你的调整，我基本同意，但你
带上我上面说的mindset看看是否有需要最终调整的内容。

## api

我看了，这个接口设计我基本同意

## 关于实施

顺序我同意。

实现的时候，专门做一个文件夹，不要和mem0共用。我们内部的功能模块，按文件夹分开，不要全部写到一个文件中。
按照工程的最佳实践，要方便后期调整维护。

## 最后

如果还有不明确的地方我们可以继续讨论。

如果你认为都明确了，那么请你起草一个详尽、全面的开发文档，把项目框架、pipeline结构、表结构、api结构等等等等详尽的写出来
（方便其他claude的实例接受，也方便后期维护，也方便人类阅读裂解模块）
类似于我最初的01-user_profile，但更加详细深入，能直接指导开发。
# 回复04-further_discussion

## 1. 关键架构决策

### 1.1 独立服务 vs 集成在 mem0 中

我同意你的方案

## 2. 基本信息的采集策略

#### 第 1 层：前端表单（用户主动填写，优先级最高）

如果前端有值，那么就采用，如果没有值，则可以写入（进入第二层）

#### 第 2 层：LLM 提取（自动填充空白字段，或检测明显变化）

关于置信度我有疑问，怎么判断置信度呢？llm的置信度是否准确呢？

#### 第 3 层：变化检测（仅在明确表述时更新）

关于第三层，其实我认为他属于第二层的另一个情况，因为这两层和第一层区别就是是否采用llm，
而2和3层的区别仅仅是字段是否已经存在

这其实就是一个核心的内部接口，由llm 1-提取信息，2-正确提取现有的相关信息，3-判断与现有信息的关系，
4-决定是新增、修改以及是否要删除现有的部分内容 5-执行操作并保存
（这个核心实现很多地方都用到，pipeline可以参考mem0中的类似接口以及类似prompt）

## 11. 关于隐私和安全的提醒

todo文件你为我生成吧

## 最后

我们可能还需要一轮沟通，所以还是先不着急开始实现。把所有问题都确认好再实现吧。

## 3. LLM 调用策略细化

### 3.1 单次 LLM 调用的输出结构

关于你的输出结构：
    "interests": {
      "add": ["football", "lego"],
      "remove": ["dolls"],  // 明确说不喜欢了
      "update": null
    },
类似这样的，就是我上面提到的核心内部接口，你参考一下mem0是怎么具体实现的吧
他的pipeline是怎么样的，是否直接就是你这样，一步输出add remove update？还是有更多的逻辑？

另外我比较担心的是：llm出现幻觉，因为一次输出的json字段越多，其中有任何一个坏了，会造成
整个批次报废，所以我比较担心。你有什么建议吗？

## 4. 兴趣变化的语义判断

你的这个例子让我想到了是不是增加一个dislike的项（但好像会让逻辑很复杂？现在是否需要？）

你给的两个策略我偏向保守策略吧，先能跑起来，后面的再说

## 5. 词汇 level 的判断标准
### 5.1 需要明确的判断标准

llm判断除了基于本次的用户prompt，还要加上历史数据，比如这个单词之前是什么水平，
count是多少，等。所以这也涉及到了单词的查询接口（之前提到的）

### 5.2 level 升级逻辑
先按照简单逻辑实现吧

### 6.2 新的配置需求
可以

## 7. 数据库迁移
### 7.1 澄清问题

目前的表结构尽量全面，如果之前有没考虑到的字段可以先加上，尽量减少以后新增
你可以根据你的判断增加我的表结构中的字段设计，我们一起确认

## 8. API 接口设计确认

接口设计参考mem0接口，比如他是/memory/search或者别的，
我们也搞一个/profile/search或者类似的
请求的方法也一样

## 9. 测试策略

测试是否要现在确定，是否可以等基本实现完成再考虑？还是说会影响到开发实现的设计？